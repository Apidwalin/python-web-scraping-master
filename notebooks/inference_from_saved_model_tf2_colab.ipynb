{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cT5cdSLPX0ui"
   },
   "source": [
    "# Intro to Object Detection Colab\n",
    "\n",
    "Welcome to the object detection colab! This demo will take you through the steps of running an \"out-of-the-box\" detection model in SavedModel format on a collection of images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBzb04bdNGM8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2.0\n",
      "  Downloading tensorflow-2.2.0-cp37-cp37m-win_amd64.whl (459.2 MB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.18.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (0.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (3.17.3)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.34.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\apidwalin\\anaconda3\\envs\\tensorflow1\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, scipy, h5py, gast, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.0\n",
      "    Uninstalling scipy-1.7.0:\n",
      "      Successfully uninstalled scipy-1.7.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "Successfully installed gast-0.3.3 h5py-2.10.0 scipy-1.4.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.5.0 requires gast==0.4.0, but you have gast 0.3.3 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires numpy~=1.19.2, but you have numpy 1.18.1 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires six~=1.15.0, but you have six 1.14.0 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.2.2 which is incompatible.\n",
      "tensorflow-gpu 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 2.2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --pre tensorflow==\"2.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgSXyvKSNHIl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhpPgW7TNLs6"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-1cb5b0736a81>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-1cb5b0736a81>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    cd models/research/\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yn5_uV1HLvaz"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import six\n",
    "import time\n",
    "\n",
    "from six import BytesIO\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-y9R0Xllefec"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: a file path (this can be local or on colossus)\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Load the COCO Label Map\n",
    "category_index = {\n",
    "    1: {'id': 1, 'name': 'person'},\n",
    "    2: {'id': 2, 'name': 'bicycle'},\n",
    "    3: {'id': 3, 'name': 'car'},\n",
    "    4: {'id': 4, 'name': 'motorcycle'},\n",
    "    5: {'id': 5, 'name': 'airplane'},\n",
    "    6: {'id': 6, 'name': 'bus'},\n",
    "    7: {'id': 7, 'name': 'train'},\n",
    "    8: {'id': 8, 'name': 'truck'},\n",
    "    9: {'id': 9, 'name': 'boat'},\n",
    "    10: {'id': 10, 'name': 'traffic light'},\n",
    "    11: {'id': 11, 'name': 'fire hydrant'},\n",
    "    13: {'id': 13, 'name': 'stop sign'},\n",
    "    14: {'id': 14, 'name': 'parking meter'},\n",
    "    15: {'id': 15, 'name': 'bench'},\n",
    "    16: {'id': 16, 'name': 'bird'},\n",
    "    17: {'id': 17, 'name': 'cat'},\n",
    "    18: {'id': 18, 'name': 'dog'},\n",
    "    19: {'id': 19, 'name': 'horse'},\n",
    "    20: {'id': 20, 'name': 'sheep'},\n",
    "    21: {'id': 21, 'name': 'cow'},\n",
    "    22: {'id': 22, 'name': 'elephant'},\n",
    "    23: {'id': 23, 'name': 'bear'},\n",
    "    24: {'id': 24, 'name': 'zebra'},\n",
    "    25: {'id': 25, 'name': 'giraffe'},\n",
    "    27: {'id': 27, 'name': 'backpack'},\n",
    "    28: {'id': 28, 'name': 'umbrella'},\n",
    "    31: {'id': 31, 'name': 'handbag'},\n",
    "    32: {'id': 32, 'name': 'tie'},\n",
    "    33: {'id': 33, 'name': 'suitcase'},\n",
    "    34: {'id': 34, 'name': 'frisbee'},\n",
    "    35: {'id': 35, 'name': 'skis'},\n",
    "    36: {'id': 36, 'name': 'snowboard'},\n",
    "    37: {'id': 37, 'name': 'sports ball'},\n",
    "    38: {'id': 38, 'name': 'kite'},\n",
    "    39: {'id': 39, 'name': 'baseball bat'},\n",
    "    40: {'id': 40, 'name': 'baseball glove'},\n",
    "    41: {'id': 41, 'name': 'skateboard'},\n",
    "    42: {'id': 42, 'name': 'surfboard'},\n",
    "    43: {'id': 43, 'name': 'tennis racket'},\n",
    "    44: {'id': 44, 'name': 'bottle'},\n",
    "    46: {'id': 46, 'name': 'wine glass'},\n",
    "    47: {'id': 47, 'name': 'cup'},\n",
    "    48: {'id': 48, 'name': 'fork'},\n",
    "    49: {'id': 49, 'name': 'knife'},\n",
    "    50: {'id': 50, 'name': 'spoon'},\n",
    "    51: {'id': 51, 'name': 'bowl'},\n",
    "    52: {'id': 52, 'name': 'banana'},\n",
    "    53: {'id': 53, 'name': 'apple'},\n",
    "    54: {'id': 54, 'name': 'sandwich'},\n",
    "    55: {'id': 55, 'name': 'orange'},\n",
    "    56: {'id': 56, 'name': 'broccoli'},\n",
    "    57: {'id': 57, 'name': 'carrot'},\n",
    "    58: {'id': 58, 'name': 'hot dog'},\n",
    "    59: {'id': 59, 'name': 'pizza'},\n",
    "    60: {'id': 60, 'name': 'donut'},\n",
    "    61: {'id': 61, 'name': 'cake'},\n",
    "    62: {'id': 62, 'name': 'chair'},\n",
    "    63: {'id': 63, 'name': 'couch'},\n",
    "    64: {'id': 64, 'name': 'potted plant'},\n",
    "    65: {'id': 65, 'name': 'bed'},\n",
    "    67: {'id': 67, 'name': 'dining table'},\n",
    "    70: {'id': 70, 'name': 'toilet'},\n",
    "    72: {'id': 72, 'name': 'tv'},\n",
    "    73: {'id': 73, 'name': 'laptop'},\n",
    "    74: {'id': 74, 'name': 'mouse'},\n",
    "    75: {'id': 75, 'name': 'remote'},\n",
    "    76: {'id': 76, 'name': 'keyboard'},\n",
    "    77: {'id': 77, 'name': 'cell phone'},\n",
    "    78: {'id': 78, 'name': 'microwave'},\n",
    "    79: {'id': 79, 'name': 'oven'},\n",
    "    80: {'id': 80, 'name': 'toaster'},\n",
    "    81: {'id': 81, 'name': 'sink'},\n",
    "    82: {'id': 82, 'name': 'refrigerator'},\n",
    "    84: {'id': 84, 'name': 'book'},\n",
    "    85: {'id': 85, 'name': 'clock'},\n",
    "    86: {'id': 86, 'name': 'vase'},\n",
    "    87: {'id': 87, 'name': 'scissors'},\n",
    "    88: {'id': 88, 'name': 'teddy bear'},\n",
    "    89: {'id': 89, 'name': 'hair drier'},\n",
    "    90: {'id': 90, 'name': 'toothbrush'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwcBC2TlPSwg"
   },
   "outputs": [],
   "source": [
    "# Download the saved model and put it into models/research/object_detection/test_data/\n",
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d5_coco17_tpu-32.tar.gz\n",
    "!tar -xf efficientdet_d5_coco17_tpu-32.tar.gz\n",
    "!mv efficientdet_d5_coco17_tpu-32/ models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2p-PmKLYCVU"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tf.keras.backend.clear_session()\n",
    "detect_fn = tf.saved_model.load('models/research/object_detection/test_data/efficientdet_d5_coco17_tpu-32/saved_model/')\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Elapsed time: ' + str(elapsed_time) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vukkhd5-9NSL"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image_dir = 'models/research/object_detection/test_images'\n",
    "\n",
    "elapsed = []\n",
    "for i in range(2):\n",
    "  image_path = os.path.join(image_dir, 'image' + str(i + 1) + '.jpg')\n",
    "  image_np = load_image_into_numpy_array(image_path)\n",
    "  input_tensor = np.expand_dims(image_np, 0)\n",
    "  start_time = time.time()\n",
    "  detections = detect_fn(input_tensor)\n",
    "  end_time = time.time()\n",
    "  elapsed.append(end_time - start_time)\n",
    "\n",
    "  plt.rcParams['figure.figsize'] = [42, 21]\n",
    "  label_id_offset = 1\n",
    "  image_np_with_detections = image_np.copy()\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'][0].numpy(),\n",
    "        detections['detection_classes'][0].numpy().astype(np.int32),\n",
    "        detections['detection_scores'][0].numpy(),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=.40,\n",
    "        agnostic_mode=False)\n",
    "  plt.subplot(2, 1, i+1)\n",
    "  plt.imshow(image_np_with_detections)\n",
    "\n",
    "mean_elapsed = sum(elapsed) / float(len(elapsed))\n",
    "print('Elapsed time: ' + str(mean_elapsed) + ' second per image')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "inference_from_saved_model_tf2_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
